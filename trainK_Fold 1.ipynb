{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 16:20:47.710209: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-01 16:20:47.710249: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-01 16:20:47.710281: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-01 16:20:47.717117: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data_split = open('data_split.csv', 'rb')\n",
    "data = pickle.load(file_data_split)\n",
    "x_data,y_data = data\n",
    "file_data_split.close()\n",
    "\n",
    "x_train = np.concatenate((x_data[1], x_data[2],x_data[3]),axis=0)\n",
    "y_train = np.concatenate((y_data[1], y_data[2],y_data[3]),axis= 0)\n",
    "x_test = x_data[0]\n",
    "y_test = y_data[0]\n",
    "\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "y_train=encoder.fit_transform(y_train)\n",
    "y_test=encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history():\n",
    "\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(accuracy, label='Training Accuracy')\n",
    "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)  \n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 128)       204928    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 3, 3, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1, 1, 256)         1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1232771 (4.70 MB)\n",
      "Trainable params: 1232259 (4.70 MB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 16:20:49.420623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.426233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.426500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.428185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.428477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.428692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.936517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.936788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.937011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-01 16:20:49.937170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 359 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = x_test[1].shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='MSE', metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model_1.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 16:20:59.083484: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 201949184 exceeds 10% of free system memory.\n",
      "2023-11-01 16:21:09.261141: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 192.59MiB (rounded to 201949184)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-01 16:21:09.261170: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-01 16:21:09.261181: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 39, Chunks in use: 39. 9.8KiB allocated for chunks. 9.8KiB in use in bin. 1.7KiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261188: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 9, Chunks in use: 9. 5.2KiB allocated for chunks. 5.2KiB in use in bin. 5.2KiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261195: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 12, Chunks in use: 12. 12.2KiB allocated for chunks. 12.2KiB in use in bin. 12.0KiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261202: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 3, Chunks in use: 3. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 6.0KiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261209: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 3, Chunks in use: 3. 18.8KiB allocated for chunks. 18.8KiB in use in bin. 18.8KiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261216: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261223: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261230: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 3, Chunks in use: 3. 101.5KiB allocated for chunks. 101.5KiB in use in bin. 96.0KiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261237: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0. 124.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261243: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261250: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 3, Chunks in use: 3. 768.0KiB allocated for chunks. 768.0KiB in use in bin. 768.0KiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261257: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 7, Chunks in use: 7. 4.41MiB allocated for chunks. 4.41MiB in use in bin. 4.12MiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261263: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261270: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 2, Chunks in use: 2. 6.25MiB allocated for chunks. 6.25MiB in use in bin. 6.25MiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261276: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 4.69MiB allocated for chunks. 4.69MiB in use in bin. 3.12MiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261283: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261289: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261297: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261304: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261311: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 2, Chunks in use: 1. 342.95MiB allocated for chunks. 192.59MiB in use in bin. 192.59MiB client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261318: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-01 16:21:09.261325: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 192.59MiB was 128.00MiB, Chunk State: \n",
      "2023-11-01 16:21:09.261336: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 150.35MiB | Requested Size: 2.00MiB | in_use: 0 | bin_num: 19, prev:   Size: 256.0KiB | Requested Size: 256.0KiB | in_use: 1 | bin_num: -1\n",
      "2023-11-01 16:21:09.261342: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 376766464\n",
      "2023-11-01 16:21:09.261349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000000 of size 256 next 1\n",
      "2023-11-01 16:21:09.261355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000100 of size 1280 next 2\n",
      "2023-11-01 16:21:09.261361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000600 of size 256 next 3\n",
      "2023-11-01 16:21:09.261367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000700 of size 256 next 4\n",
      "2023-11-01 16:21:09.261373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000800 of size 256 next 6\n",
      "2023-11-01 16:21:09.261378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000900 of size 256 next 7\n",
      "2023-11-01 16:21:09.261384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000a00 of size 256 next 5\n",
      "2023-11-01 16:21:09.261390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000b00 of size 256 next 8\n",
      "2023-11-01 16:21:09.261396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000c00 of size 512 next 13\n",
      "2023-11-01 16:21:09.261402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000e00 of size 256 next 11\n",
      "2023-11-01 16:21:09.261407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54000f00 of size 256 next 12\n",
      "2023-11-01 16:21:09.261413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54001000 of size 1024 next 18\n",
      "2023-11-01 16:21:09.261419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54001400 of size 256 next 16\n",
      "2023-11-01 16:21:09.261424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54001500 of size 1024 next 17\n",
      "2023-11-01 16:21:09.261430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54001900 of size 1024 next 21\n",
      "2023-11-01 16:21:09.261436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54001d00 of size 1024 next 22\n",
      "2023-11-01 16:21:09.261441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54002100 of size 1024 next 23\n",
      "2023-11-01 16:21:09.261447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54002500 of size 256 next 24\n",
      "2023-11-01 16:21:09.261453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54002600 of size 256 next 25\n",
      "2023-11-01 16:21:09.261459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54002700 of size 2048 next 28\n",
      "2023-11-01 16:21:09.261464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54002f00 of size 256 next 26\n",
      "2023-11-01 16:21:09.261470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003000 of size 256 next 27\n",
      "2023-11-01 16:21:09.261477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003100 of size 512 next 32\n",
      "2023-11-01 16:21:09.261483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003300 of size 256 next 29\n",
      "2023-11-01 16:21:09.261488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003400 of size 256 next 31\n",
      "2023-11-01 16:21:09.261494: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003500 of size 256 next 37\n",
      "2023-11-01 16:21:09.261500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003600 of size 256 next 35\n",
      "2023-11-01 16:21:09.261505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003700 of size 256 next 36\n",
      "2023-11-01 16:21:09.261511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003800 of size 256 next 45\n",
      "2023-11-01 16:21:09.261517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003900 of size 256 next 47\n",
      "2023-11-01 16:21:09.261522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003a00 of size 256 next 48\n",
      "2023-11-01 16:21:09.261528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003b00 of size 256 next 49\n",
      "2023-11-01 16:21:09.261534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003c00 of size 256 next 9\n",
      "2023-11-01 16:21:09.261539: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54003d00 of size 6400 next 10\n",
      "2023-11-01 16:21:09.261546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54005600 of size 524288 next 34\n",
      "2023-11-01 16:21:09.261551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54085600 of size 262144 next 33\n",
      "2023-11-01 16:21:09.261559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c5600 of size 256 next 41\n",
      "2023-11-01 16:21:09.261565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c5700 of size 256 next 40\n",
      "2023-11-01 16:21:09.261571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c5800 of size 256 next 42\n",
      "2023-11-01 16:21:09.261576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c5900 of size 256 next 43\n",
      "2023-11-01 16:21:09.261582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c5a00 of size 768 next 44\n",
      "2023-11-01 16:21:09.261588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c5d00 of size 6400 next 50\n",
      "2023-11-01 16:21:09.261593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c7600 of size 6400 next 51\n",
      "2023-11-01 16:21:09.261599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c8f00 of size 256 next 52\n",
      "2023-11-01 16:21:09.261605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c9000 of size 512 next 55\n",
      "2023-11-01 16:21:09.261610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c9200 of size 512 next 56\n",
      "2023-11-01 16:21:09.261616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c9400 of size 1024 next 58\n",
      "2023-11-01 16:21:09.261622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c9800 of size 1024 next 59\n",
      "2023-11-01 16:21:09.261628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540c9c00 of size 1024 next 60\n",
      "2023-11-01 16:21:09.261633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540ca000 of size 1024 next 61\n",
      "2023-11-01 16:21:09.261639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540ca400 of size 1024 next 62\n",
      "2023-11-01 16:21:09.261645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540ca800 of size 1024 next 63\n",
      "2023-11-01 16:21:09.261650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540cac00 of size 2048 next 66\n",
      "2023-11-01 16:21:09.261656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540cb400 of size 2048 next 67\n",
      "2023-11-01 16:21:09.261662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540cbc00 of size 512 next 70\n",
      "2023-11-01 16:21:09.261667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540cbe00 of size 512 next 71\n",
      "2023-11-01 16:21:09.261674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540cc000 of size 38400 next 39\n",
      "2023-11-01 16:21:09.261680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540d5600 of size 32768 next 38\n",
      "2023-11-01 16:21:09.261686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540dd600 of size 32768 next 72\n",
      "2023-11-01 16:21:09.261692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e5600 of size 256 next 73\n",
      "2023-11-01 16:21:09.261697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e5700 of size 256 next 74\n",
      "2023-11-01 16:21:09.261703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e5800 of size 768 next 75\n",
      "2023-11-01 16:21:09.261709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e5b00 of size 768 next 76\n",
      "2023-11-01 16:21:09.261715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e5e00 of size 256 next 77\n",
      "2023-11-01 16:21:09.261720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e5f00 of size 256 next 78\n",
      "2023-11-01 16:21:09.261726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e6000 of size 256 next 79\n",
      "2023-11-01 16:21:09.261732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e6100 of size 256 next 80\n",
      "2023-11-01 16:21:09.261737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e6200 of size 256 next 81\n",
      "2023-11-01 16:21:09.261743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e6300 of size 256 next 82\n",
      "2023-11-01 16:21:09.261749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e6400 of size 256 next 83\n",
      "2023-11-01 16:21:09.261754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba540e6500 of size 256 next 84\n",
      "2023-11-01 16:21:09.261760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fba540e6600 of size 126976 next 30\n",
      "2023-11-01 16:21:09.261766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54105600 of size 589824 next 15\n",
      "2023-11-01 16:21:09.261772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54195600 of size 819200 next 14\n",
      "2023-11-01 16:21:09.261777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba5425d600 of size 819200 next 53\n",
      "2023-11-01 16:21:09.261783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54325600 of size 819200 next 54\n",
      "2023-11-01 16:21:09.261789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba543ed600 of size 4915200 next 20\n",
      "2023-11-01 16:21:09.261795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba5489d600 of size 3276800 next 19\n",
      "2023-11-01 16:21:09.261801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba54bbd600 of size 201949184 next 46\n",
      "2023-11-01 16:21:09.261808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba60c55600 of size 3276800 next 57\n",
      "2023-11-01 16:21:09.261814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba60f75600 of size 524288 next 64\n",
      "2023-11-01 16:21:09.261819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba60ff5600 of size 524288 next 65\n",
      "2023-11-01 16:21:09.261825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba61075600 of size 262144 next 68\n",
      "2023-11-01 16:21:09.261831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fba610b5600 of size 262144 next 69\n",
      "2023-11-01 16:21:09.261837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fba610f5600 of size 157657600 next 18446744073709551615\n",
      "2023-11-01 16:21:09.261843: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-11-01 16:21:09.261850: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 39 Chunks of size 256 totalling 9.8KiB\n",
      "2023-11-01 16:21:09.261857: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 512 totalling 3.0KiB\n",
      "2023-11-01 16:21:09.261863: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 768 totalling 2.2KiB\n",
      "2023-11-01 16:21:09.261870: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 11 Chunks of size 1024 totalling 11.0KiB\n",
      "2023-11-01 16:21:09.261877: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-11-01 16:21:09.261883: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2048 totalling 6.0KiB\n",
      "2023-11-01 16:21:09.261889: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 6400 totalling 18.8KiB\n",
      "2023-11-01 16:21:09.261895: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 32768 totalling 64.0KiB\n",
      "2023-11-01 16:21:09.261901: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 38400 totalling 37.5KiB\n",
      "2023-11-01 16:21:09.261908: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 262144 totalling 768.0KiB\n",
      "2023-11-01 16:21:09.261914: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 524288 totalling 1.50MiB\n",
      "2023-11-01 16:21:09.261920: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2023-11-01 16:21:09.261926: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 819200 totalling 2.34MiB\n",
      "2023-11-01 16:21:09.261932: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 3276800 totalling 6.25MiB\n",
      "2023-11-01 16:21:09.261938: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4915200 totalling 4.69MiB\n",
      "2023-11-01 16:21:09.261945: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 201949184 totalling 192.59MiB\n",
      "2023-11-01 16:21:09.261951: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 208.84MiB\n",
      "2023-11-01 16:21:09.261957: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 376766464 memory_limit_: 376766464 available bytes: 0 curr_region_allocation_bytes_: 753532928\n",
      "2023-11-01 16:21:09.261966: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       376766464\n",
      "InUse:                       218981888\n",
      "MaxInUse:                    376651520\n",
      "NumAllocs:                         128\n",
      "MaxAllocSize:                201949184\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-01 16:21:09.261975: W tensorflow/tsl/framework/bfc_allocator.cc:497] ***********************************************************_________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/duyphuoc/Desktop/heart_sound_new/trainK_Fold 1.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/duyphuoc/Desktop/heart_sound_new/trainK_Fold%201.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train,y_train,batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(x_test, y_test), callbacks\u001b[39m=\u001b[39;49m[model_checkpoint])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/duyphuoc/Desktop/heart_sound_new/trainK_Fold%201.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m show_history()\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=128, epochs=30,validation_data=(x_test, y_test), callbacks=[model_checkpoint])\n",
    "show_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
