{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history():\n",
    "\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(accuracy, label='Training Accuracy')\n",
    "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)  \n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.05*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "# def pitch(data, sampling_rate, pitch_factor=0.8):\n",
    "#     return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def higher_speed(data):\n",
    "    return librosa.effects.time_stretch(data, rate=1.2)\n",
    "\n",
    "def lower_speed(data):\n",
    "    return librosa.effects.time_stretch(data, rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(label):\n",
    "    # print(folders)\n",
    "    y_data.append(label)\n",
    "    \n",
    "def get_data_chroma(name_files,audio,time_limit,sr):\n",
    "\n",
    "    segment_length = time_limit * sr\n",
    "    num_segments = (len(audio) // segment_length)\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_length\n",
    "        end_sample = (i + 1) * segment_length\n",
    "        segment = audio[start_sample:end_sample]\n",
    "\n",
    "        create_data_chroma(segment,n_fft,hop_length)\n",
    "\n",
    "        label = name_files.split('/')[1]\n",
    "        get_label(label)\n",
    "def create_data_chroma (audio,n_fft,hop_length):\n",
    "    S = np.abs(librosa.stft(audio,n_fft=512,hop_length=256))**5\n",
    "    chromagram = librosa.feature.chroma_stft(S=S, sr=sr)\n",
    "    chromagram = cv2.resize(chromagram, (64,64))\n",
    "    chromagram= np.resize(chromagram,(64,64,1))\n",
    "    x_data.append(chromagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft=512\n",
    "hop_length=256\n",
    "sr=4000\n",
    "time_limit = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duyphuoc/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8686, 64, 64, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "dem = 0\n",
    "name_folders = \"training_data_all/Absent\"\n",
    "for file in os.listdir(name_folders):\n",
    "    if(dem>1600):\n",
    "        name_files = os.path.join(name_folders,file)\n",
    "        audio, sr = librosa.load(name_files, sr=sr)\n",
    "        get_data_chroma(name_files,audio,time_limit = time_limit,sr = sr)\n",
    "    dem = dem +1 \n",
    "x_absent_chroma= x_data\n",
    "y_absent_chroma = y_data\n",
    "np.array(x_absent_chroma).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6548, 64, 64, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "dem = 0\n",
    "name_folders = \"training_data_all/Present\"\n",
    "for file in os.listdir(name_folders):\n",
    "    if(True):\n",
    "        name_files = os.path.join(name_folders,file)\n",
    "        audio, sr = librosa.load(name_files, sr=sr)\n",
    "        get_data_chroma(name_files,audio,time_limit = time_limit,sr = sr)\n",
    "    dem = dem +1\n",
    "x_present_chroma = x_data\n",
    "y_present_chroma = y_data\n",
    "np.array(x_present_chroma).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662, 64, 64, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "dem = 0\n",
    "name_folders = \"training_data_all/Unknown\"\n",
    "for file in os.listdir(name_folders):\n",
    "    if(True):\n",
    "        name_files = os.path.join(name_folders,file)\n",
    "        audio, sr = librosa.load(name_files, sr=sr)\n",
    "        get_data_chroma(name_files,audio,time_limit = time_limit,sr = sr)\n",
    "    dem = dem +1\n",
    "x_unknown_chroma1 = x_data\n",
    "y_unknown_chroma1 = y_data\n",
    "np.array(x_unknown_chroma1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662, 64, 64, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "dem = 0\n",
    "name_folders = \"training_data_all/Unknown\"\n",
    "for file in os.listdir(name_folders):\n",
    "    if(True):\n",
    "        name_files = os.path.join(name_folders,file)\n",
    "        audio, sr = librosa.load(name_files, sr=sr)\n",
    "        get_data_chroma(name_files,noise(audio),time_limit = time_limit,sr = sr)\n",
    "    dem = dem +1\n",
    "x_unknown_chroma2 = x_data\n",
    "y_unknown_chroma2 = y_data\n",
    "np.array(x_unknown_chroma2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1381, 64, 64, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "dem = 0\n",
    "name_folders = \"training_data_all/Unknown\"\n",
    "for file in os.listdir(name_folders):\n",
    "    if(True):\n",
    "        name_files = os.path.join(name_folders,file)\n",
    "        audio, sr = librosa.load(name_files, sr=sr)\n",
    "        get_data_chroma(name_files,higher_speed(audio),time_limit = time_limit,sr = sr)\n",
    "    dem = dem +1\n",
    "x_unknown_chroma3 = x_data\n",
    "y_unknown_chroma3 = y_data\n",
    "np.array(x_unknown_chroma3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2110, 64, 64, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "dem = 0\n",
    "name_folders = \"training_data_all/Unknown\"\n",
    "for file in os.listdir(name_folders):\n",
    "    if(True):\n",
    "        name_files = os.path.join(name_folders,file)\n",
    "        audio, sr = librosa.load(name_files, sr=sr)\n",
    "        get_data_chroma(name_files,lower_speed(audio),time_limit = time_limit,sr = sr)\n",
    "    dem = dem +1\n",
    "x_unknown_chroma4 = x_data\n",
    "y_unknown_chroma4 = y_data\n",
    "np.array(x_unknown_chroma4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_chroma = np.concatenate((x_absent_chroma,\n",
    "                                     x_present_chroma,\n",
    "                                     x_unknown_chroma1,\n",
    "                                     x_unknown_chroma2,\n",
    "                                     x_unknown_chroma3,\n",
    "                                     x_unknown_chroma4),axis=0)\n",
    "y_data_chroma = np.concatenate((y_absent_chroma,\n",
    "                                     y_present_chroma,\n",
    "                                     y_unknown_chroma1,\n",
    "                                     y_unknown_chroma2,\n",
    "                                     y_unknown_chroma3,\n",
    "                                     y_unknown_chroma4),axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22049, 64, 64, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_chroma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_all = []\n",
    "x_data_all.append(x_data_chroma)\n",
    "\n",
    "y_data_all = []\n",
    "y_data_all.append(y_data_chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = open('data_chroma.csv','wb')\n",
    "pickle.dump((x_data_all,y_data_all),file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data_chroma.csv', 'rb')\n",
    "data = pickle.load(file)\n",
    "x_data,y_data =data\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "x_train = []\n",
    "y_train = []\n",
    "encoder = LabelBinarizer()\n",
    "y_data=encoder.fit_transform(y_data[0])\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_data[0],y_data,test_size=0.2,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x_test[1].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_96 (Conv2D)          (None, 64, 64, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_96 (Ba  (None, 64, 64, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_97 (Ba  (None, 64, 64, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPooli  (None, 32, 32, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_98 (Ba  (None, 32, 32, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_99 (Ba  (None, 32, 32, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPooli  (None, 16, 16, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_100 (Conv2D)         (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_100 (B  (None, 16, 16, 256)       1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_101 (B  (None, 16, 16, 256)       1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_102 (Conv2D)         (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_102 (B  (None, 16, 16, 256)       1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 8, 8, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_103 (B  (None, 8, 8, 256)         1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_104 (B  (None, 8, 8, 256)         1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_105 (B  (None, 8, 8, 256)         1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 4, 4, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_106 (B  (None, 4, 4, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_107 (B  (None, 4, 4, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_108 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_108 (B  (None, 4, 4, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_109 (B  (None, 4, 4, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_110 (B  (None, 4, 4, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_111 (B  (None, 4, 4, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (None, 2, 2, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19654595 (74.98 MB)\n",
      "Trainable params: 19644611 (74.94 MB)\n",
      "Non-trainable params: 9984 (39.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 1\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 2\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "# # Lớp Convolution và Batch Normalization (BN) - Block 4\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 5\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Lớp Fully Connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dense(4096, activation='relu'))\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 16:46:35.176213: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 288997376 exceeds 10% of free system memory.\n",
      "2023-11-16 16:46:35.548622: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 288997376 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 16:46:40.801761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-16 16:46:43.128053: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0ec002efc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-16 16:46:43.128093: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-11-16 16:46:43.146961: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-16 16:46:43.270743: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276/276 [==============================] - ETA: 0s - loss: 1.1066 - accuracy: 0.5045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 16:47:13.740200: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 72253440 exceeds 10% of free system memory.\n",
      "2023-11-16 16:47:13.843816: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 72253440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.30408, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duyphuoc/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276/276 [==============================] - 41s 98ms/step - loss: 1.1066 - accuracy: 0.5045 - val_loss: 9.3870 - val_accuracy: 0.3041\n",
      "Epoch 2/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.9317 - accuracy: 0.5395\n",
      "Epoch 2: val_accuracy improved from 0.30408 to 0.30658, saving model to best_model.h5\n",
      "276/276 [==============================] - 24s 87ms/step - loss: 0.9317 - accuracy: 0.5395 - val_loss: 7.6609 - val_accuracy: 0.3066\n",
      "Epoch 3/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.9149 - accuracy: 0.5576\n",
      "Epoch 3: val_accuracy improved from 0.30658 to 0.56735, saving model to best_model.h5\n",
      "276/276 [==============================] - 24s 87ms/step - loss: 0.9149 - accuracy: 0.5576 - val_loss: 0.9411 - val_accuracy: 0.5673\n",
      "Epoch 4/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.8943 - accuracy: 0.5712\n",
      "Epoch 4: val_accuracy did not improve from 0.56735\n",
      "276/276 [==============================] - 24s 86ms/step - loss: 0.8943 - accuracy: 0.5712 - val_loss: 0.9293 - val_accuracy: 0.5673\n",
      "Epoch 5/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.8764 - accuracy: 0.5889\n",
      "Epoch 5: val_accuracy did not improve from 0.56735\n",
      "276/276 [==============================] - 24s 87ms/step - loss: 0.8764 - accuracy: 0.5889 - val_loss: 0.9558 - val_accuracy: 0.5202\n",
      "Epoch 6/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.8698 - accuracy: 0.5968\n",
      "Epoch 6: val_accuracy improved from 0.56735 to 0.57166, saving model to best_model.h5\n",
      "276/276 [==============================] - 25s 89ms/step - loss: 0.8698 - accuracy: 0.5968 - val_loss: 0.9537 - val_accuracy: 0.5717\n",
      "Epoch 7/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.8467 - accuracy: 0.6139\n",
      "Epoch 7: val_accuracy did not improve from 0.57166\n",
      "276/276 [==============================] - 25s 90ms/step - loss: 0.8467 - accuracy: 0.6139 - val_loss: 1.2856 - val_accuracy: 0.5517\n",
      "Epoch 8/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.8205 - accuracy: 0.6248\n",
      "Epoch 8: val_accuracy did not improve from 0.57166\n",
      "276/276 [==============================] - 24s 88ms/step - loss: 0.8205 - accuracy: 0.6248 - val_loss: 1.0050 - val_accuracy: 0.5710\n",
      "Epoch 9/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.7966 - accuracy: 0.6364\n",
      "Epoch 9: val_accuracy did not improve from 0.57166\n",
      "276/276 [==============================] - 24s 87ms/step - loss: 0.7966 - accuracy: 0.6364 - val_loss: 0.9495 - val_accuracy: 0.5678\n",
      "Epoch 10/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.7725 - accuracy: 0.6522\n",
      "Epoch 10: val_accuracy did not improve from 0.57166\n",
      "276/276 [==============================] - 24s 87ms/step - loss: 0.7725 - accuracy: 0.6522 - val_loss: 1.0183 - val_accuracy: 0.5653\n",
      "Epoch 11/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.7430 - accuracy: 0.6678\n",
      "Epoch 11: val_accuracy did not improve from 0.57166\n",
      "276/276 [==============================] - 24s 87ms/step - loss: 0.7430 - accuracy: 0.6678 - val_loss: 1.2688 - val_accuracy: 0.5116\n",
      "Epoch 12/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.7039 - accuracy: 0.6897\n",
      "Epoch 12: val_accuracy did not improve from 0.57166\n",
      "276/276 [==============================] - 24s 87ms/step - loss: 0.7039 - accuracy: 0.6897 - val_loss: 0.9884 - val_accuracy: 0.5512\n",
      "Epoch 13/38\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.6585 - accuracy: 0.7146\n",
      "Epoch 13: val_accuracy did not improve from 0.57166\n",
      "276/276 [==============================] - 24s 86ms/step - loss: 0.6585 - accuracy: 0.7146 - val_loss: 1.0692 - val_accuracy: 0.5465\n",
      "Epoch 14/38\n",
      "101/276 [=========>....................] - ETA: 13s - loss: 0.5744 - accuracy: 0.7543"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/duyphuoc/Desktop/heart_sound_new/chroma.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/duyphuoc/Desktop/heart_sound_new/chroma.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train,y_train,batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m38\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(x_test, y_test), callbacks\u001b[39m=\u001b[39;49m[model_checkpoint])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/duyphuoc/Desktop/heart_sound_new/chroma.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m show_history()\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/heart_sound_new/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=64, epochs=38,validation_data=(x_test, y_test), callbacks=[model_checkpoint])\n",
    "show_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
