{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data_all.csv', 'rb')\n",
    "data = pickle.load(file)\n",
    "x_data,y_data = data\n",
    "file.close()\n",
    "x_data = np.concatenate((x_data[0], x_data[1],x_data[2]),axis=0)\n",
    "y_data = np.concatenate((y_data[0], y_data[1],y_data[2]),axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "x_train = []\n",
    "y_train = []\n",
    "encoder = LabelBinarizer()\n",
    "y_data =encoder.fit_transform(y_data)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46505, 64, 64, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history():\n",
    "\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(accuracy, label='Training Accuracy')\n",
    "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)  \n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 09:18:12.674568: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-08 09:18:12.674599: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-08 09:18:12.674632: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-08 09:18:12.682054: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-08 09:18:14.096742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.105287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.105450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.106261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.106412: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.106542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.612784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.612961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.613101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-08 09:18:14.613217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1931 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64, 64, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64, 64, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32, 32, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 8, 8, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 8, 8, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 8, 8, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 4, 4, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 4, 4, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 4, 4, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 2, 2, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 6147      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16219491 (61.87 MB)\n",
      "Trainable params: 16213731 (61.85 MB)\n",
      "Non-trainable params: 5760 (22.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "\n",
    "# Khởi tạo mô hình LSTM 2D\n",
    "input_shape = x_test[1].shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Tạo lớp Conv2D đầu tiên để chuyển hình ảnh xám thành 3 kênh (nhưng vẫn giữ nguyên kích thước 64x64)\n",
    "# model.add(Conv2D(3, (3, 3), activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 4\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "# Lớp Convolution và Batch Normalization (BN) - Block 5\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Lớp Fully Connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # Thay num_classes bằng số lớp phân loại thực tế\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 09:18:21.466880: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 761937920 exceeds 10% of free system memory.\n",
      "2023-11-08 09:18:22.111883: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 761937920 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 09:18:25.530642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-08 09:18:26.942702: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 764.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-08 09:18:27.038792: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-08 09:18:27.131388: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3a7cdd0380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-08 09:18:27.131411: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 3GB, Compute Capability 6.1\n",
      "2023-11-08 09:18:27.135631: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-08 09:18:27.222828: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-11-08 09:18:28.170056: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-08 09:18:28.722601: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 764.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/727 [============================>.] - ETA: 0s - loss: 0.9741 - accuracy: 0.5415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 09:19:23.093331: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-08 09:19:23.228851: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/727 [==============================] - ETA: 0s - loss: 0.9739 - accuracy: 0.5416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 09:19:24.412993: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 326565888 exceeds 10% of free system memory.\n",
      "2023-11-08 09:19:24.677468: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 326565888 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/727 [==============================] - 69s 82ms/step - loss: 0.9739 - accuracy: 0.5416 - val_loss: 1.4910 - val_accuracy: 0.5160\n",
      "Epoch 2/50\n",
      "  2/727 [..............................] - ETA: 51s - loss: 0.7805 - accuracy: 0.6328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 09:19:31.399921: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/727 [==============================] - 58s 80ms/step - loss: 0.8155 - accuracy: 0.6048 - val_loss: 1.2719 - val_accuracy: 0.4852\n",
      "Epoch 3/50\n",
      "727/727 [==============================] - 56s 77ms/step - loss: 0.7886 - accuracy: 0.6222 - val_loss: 1.1160 - val_accuracy: 0.5152\n",
      "Epoch 4/50\n",
      "727/727 [==============================] - 56s 77ms/step - loss: 0.7715 - accuracy: 0.6312 - val_loss: 1.0366 - val_accuracy: 0.6076\n",
      "Epoch 5/50\n",
      "727/727 [==============================] - 56s 77ms/step - loss: 0.7523 - accuracy: 0.6429 - val_loss: 0.9611 - val_accuracy: 0.5573\n",
      "Epoch 6/50\n",
      "727/727 [==============================] - 56s 77ms/step - loss: 0.7464 - accuracy: 0.6459 - val_loss: 1.0747 - val_accuracy: 0.5559\n",
      "Epoch 7/50\n",
      "727/727 [==============================] - 61s 83ms/step - loss: 0.7316 - accuracy: 0.6510 - val_loss: 0.9875 - val_accuracy: 0.6103\n",
      "Epoch 8/50\n",
      "727/727 [==============================] - 59s 82ms/step - loss: 0.7285 - accuracy: 0.6544 - val_loss: 0.9907 - val_accuracy: 0.5819\n",
      "Epoch 9/50\n",
      "727/727 [==============================] - 57s 78ms/step - loss: 0.7190 - accuracy: 0.6590 - val_loss: 1.5531 - val_accuracy: 0.5793\n",
      "Epoch 10/50\n",
      "727/727 [==============================] - 57s 78ms/step - loss: 0.7148 - accuracy: 0.6622 - val_loss: 1.0124 - val_accuracy: 0.5607\n",
      "Epoch 11/50\n",
      "727/727 [==============================] - 57s 78ms/step - loss: 0.7022 - accuracy: 0.6686 - val_loss: 0.9738 - val_accuracy: 0.5985\n",
      "Epoch 12/50\n",
      "727/727 [==============================] - 57s 79ms/step - loss: 0.6894 - accuracy: 0.6737 - val_loss: 1.0158 - val_accuracy: 0.6113\n",
      "Epoch 13/50\n",
      "727/727 [==============================] - 57s 78ms/step - loss: 0.6786 - accuracy: 0.6798 - val_loss: 0.8197 - val_accuracy: 0.6355\n",
      "Epoch 14/50\n",
      "727/727 [==============================] - 58s 80ms/step - loss: 0.6671 - accuracy: 0.6851 - val_loss: 0.8028 - val_accuracy: 0.6368\n",
      "Epoch 15/50\n",
      "727/727 [==============================] - 58s 80ms/step - loss: 0.6624 - accuracy: 0.6863 - val_loss: 1.1139 - val_accuracy: 0.6280\n",
      "Epoch 16/50\n",
      "727/727 [==============================] - 58s 80ms/step - loss: 0.6397 - accuracy: 0.6986 - val_loss: 1.2587 - val_accuracy: 0.6283\n",
      "Epoch 17/50\n",
      "727/727 [==============================] - 57s 78ms/step - loss: 0.6325 - accuracy: 0.7013 - val_loss: 0.8108 - val_accuracy: 0.6389\n",
      "Epoch 18/50\n",
      "727/727 [==============================] - 57s 79ms/step - loss: 0.6106 - accuracy: 0.7110 - val_loss: 0.7189 - val_accuracy: 0.6682\n",
      "Epoch 19/50\n",
      "727/727 [==============================] - 58s 79ms/step - loss: 0.5933 - accuracy: 0.7213 - val_loss: 1.0835 - val_accuracy: 0.6276\n",
      "Epoch 20/50\n",
      "727/727 [==============================] - 60s 83ms/step - loss: 0.5742 - accuracy: 0.7293 - val_loss: 1.0954 - val_accuracy: 0.5431\n",
      "Epoch 21/50\n",
      "727/727 [==============================] - 57s 79ms/step - loss: 0.5489 - accuracy: 0.7413 - val_loss: 0.8500 - val_accuracy: 0.6457\n",
      "Epoch 22/50\n",
      "727/727 [==============================] - 58s 80ms/step - loss: 0.5370 - accuracy: 0.7483 - val_loss: 0.9671 - val_accuracy: 0.6322\n",
      "Epoch 23/50\n",
      "727/727 [==============================] - 57s 79ms/step - loss: 0.5153 - accuracy: 0.7579 - val_loss: 0.8579 - val_accuracy: 0.6605\n",
      "Epoch 24/50\n",
      "727/727 [==============================] - 57s 79ms/step - loss: 0.4975 - accuracy: 0.7652 - val_loss: 0.8756 - val_accuracy: 0.6122\n",
      "Epoch 25/50\n",
      "727/727 [==============================] - 57s 78ms/step - loss: 0.4998 - accuracy: 0.7660 - val_loss: 0.8909 - val_accuracy: 0.6241\n",
      "Epoch 26/50\n",
      "727/727 [==============================] - 57s 78ms/step - loss: 0.4820 - accuracy: 0.7736 - val_loss: 0.9182 - val_accuracy: 0.6769\n",
      "Epoch 27/50\n",
      "727/727 [==============================] - 59s 81ms/step - loss: 0.4549 - accuracy: 0.7874 - val_loss: 1.0144 - val_accuracy: 0.6217\n",
      "Epoch 28/50\n",
      "727/727 [==============================] - 58s 80ms/step - loss: 0.4402 - accuracy: 0.7941 - val_loss: 0.8920 - val_accuracy: 0.6585\n",
      "Epoch 29/50\n",
      "727/727 [==============================] - 57s 79ms/step - loss: 0.4273 - accuracy: 0.8009 - val_loss: 1.0467 - val_accuracy: 0.6643\n",
      "Epoch 30/50\n",
      "150/727 [=====>........................] - ETA: 42s - loss: 0.3989 - accuracy: 0.8199"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=64, epochs=50,validation_data=(x_test, y_test))\n",
    "show_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
