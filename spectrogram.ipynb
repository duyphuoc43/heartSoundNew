{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_start(name_file):\n",
    "    file_tsv = name_file[:-3]+'tsv'\n",
    "    # Đọc tệp TSV bằng pandas\n",
    "    # print(file_tsv)\n",
    "    df = pd.read_csv(file_tsv, delimiter='\\t')\n",
    "    df=df.iloc\n",
    "    df0 = df[:,0]\n",
    "    df2 = df[:,2]\n",
    "    for i in range(len(df2)):\n",
    "        if(df2[i]==1):\n",
    "            time = df0[i]\n",
    "            break\n",
    "    return df0[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chia file.wav ra moi folder\n",
    "\n",
    "# data = 'training_data'\n",
    "\n",
    "# out_file = 'training_data_all/'\n",
    "# for file in os.listdir(data):\n",
    "#     if(file.endswith(\".wav\") == True):\n",
    "\n",
    "#         name_file = os.path.join(data,file)\n",
    "#         time_begin = (time_start(name_file))\n",
    "#         file_txt = (name_file.split('_')[0])+'_'+(name_file.split('_')[1])+'.txt'\n",
    "#         # print(file_txt)\n",
    "#         df = pd.read_csv(file_txt)\n",
    "#         df=np.array(df)\n",
    "#         # print(df)\n",
    "#         if (df == '#Murmur: Absent').any().any():\n",
    "#             # print('Absent')\n",
    "#             shutil.copy(name_file, out_file +'Absent/'+str(time_begin)+'_'+file)\n",
    "#         elif (df == '#Murmur: Present').any().any():\n",
    "#             # print('Present')\n",
    "#             shutil.copy(name_file, out_file +'Present/'+str(time_begin)+'_'+file)\n",
    "#         elif (df == '#Murmur: Unknown').any().any():\n",
    "#             # print('Unknown')\n",
    "#             shutil.copy(name_file, out_file +'Unknown/'+str(time_begin)+'_'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n/training_data_all\\n        --->Unknown\\n        --->Absent\\n        --->Present\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "/training_data_all\n",
    "        --->Unknown\n",
    "        --->Absent\n",
    "        --->Present\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_spectrogram (file):\n",
    "    audio, sr = librosa.load(file,sr=4000)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr,n_fft= 200 ,n_mels=64,hop_length=300)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram ,ref=np.max)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    a =librosa.display.specshow(mel_spectrogram_db,\n",
    "                            x_axis='time',\n",
    "                            y_axis='linear',\n",
    "                            sr=sr,\n",
    "                            hop_length=512,\n",
    "                            )\n",
    "    plt.title(\"Audio Spectrogram Representation\")\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.xlabel(\"Time(s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_file_absent = \"training_data_all/Absent/0.02025_49745_TV.wav\"\n",
    "# audio_file_present = \"training_data_all/Present/0.08025_85031_AV.wav\"\n",
    "# audio_file_unknown = \"training_data_all/Unknown/0.720351_49761_MV.wav\"\n",
    "# show_spectrogram(audio_file_absent)\n",
    "# show_spectrogram(audio_file_present)\n",
    "# show_spectrogram(audio_file_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown\n",
      "Absent\n",
      "Present\n"
     ]
    }
   ],
   "source": [
    "data_train = 'training_data_all'\n",
    "data_time = []\n",
    "for folders in os.listdir(data_train):\n",
    "    print(folders)\n",
    "    name_folders = os.path.join(data_train,folders)\n",
    "    for file in os.listdir(name_folders):\n",
    "        name_files = os.path.join(name_folders,file)\n",
    "        y,sr = librosa.load(name_files,sr=4000)\n",
    "        audio_duration = (len(y)/sr)\n",
    "        data_time.append(audio_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.152"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data (audio,file,sr):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr,n_fft= 256 ,n_mels=128,hop_length=157)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram ,ref=np.max)\n",
    "    # mel_spectrogram_db = mel_spectrogram_db.reshape([128,128,1])\n",
    "    x_data.append(mel_spectrogram_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(name_files,file,time_limit,sr):\n",
    "    audio, sr = librosa.load(name_files, sr=sr)\n",
    "    file = file[:-4]\n",
    "    segment_length = time_limit * sr\n",
    "    num_segments = (len(audio) // segment_length)\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_length\n",
    "        end_sample = (i + 1) * segment_length\n",
    "\n",
    "        segment = audio[start_sample:end_sample]\n",
    "        create_data(segment,file,sr)\n",
    "        label = name_files.split('/')[1]\n",
    "        get_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(label):\n",
    "    # print(folders)\n",
    "    y_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(name_files,file,time_limit,sr = 4000):\n",
    "    # print(name_files)\n",
    "    split_audio(name_files,file,time_limit,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown\n",
      "Absent\n",
      "Present\n"
     ]
    }
   ],
   "source": [
    "data_train = 'training_data_all'\n",
    "x_data = []\n",
    "y_data = []\n",
    "for folders in os.listdir(data_train):\n",
    "    print(folders)\n",
    "    name_folders = os.path.join(data_train,folders)\n",
    "    for file in os.listdir(name_folders):\n",
    "        name_files = os.path.join(name_folders,file)\n",
    "        get_date(name_files,file,time_limit = 5,sr = 4000)\n",
    "\n",
    "\n",
    "file = open('data_file.csv','wb')\n",
    "pickle.dump((x_data,y_data),file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data_file.csv', 'rb')\n",
    "data = pickle.load(file)\n",
    "x_data,y_data =data\n",
    "file.close()\n",
    "x_data=np.array(x_data)\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown xuất hiện 622\n",
      "Absent xuất hiện 9865\n",
      "Present xuất hiện 2453\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counters = Counter(y_data)\n",
    "\n",
    "for value, count in counters.items():\n",
    "    print(f\"{value} xuất hiện {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12940, 128, 128)\n",
      "(12940,)\n"
     ]
    }
   ],
   "source": [
    "x_data=np.array(x_data)\n",
    "y_data=np.array(y_data)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "y_data=encoder.fit_transform(y_data)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.3,random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test = np.array(x_test)\n",
    "# y_test = np.array(y_test)\n",
    "# x_train = np.array(x_train)\n",
    "# y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 128, 64)           24640     \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 64, 64)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 64, 64)            256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 64, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPooli  (None, 32, 128)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 32, 128)           512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 32, 256)           164096    \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPooli  (None, 16, 256)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 16, 256)           1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 16, 128)           197120    \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 468099 (1.79 MB)\n",
      "Trainable params: 467203 (1.78 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, LSTM, Dense, Dropout\n",
    "\n",
    "input_shape = (128, 128)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))  \n",
    "\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='MSE', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/284 [==============================] - 3s 11ms/step - loss: 0.1056 - accuracy: 0.8042 - val_loss: 0.1175 - val_accuracy: 0.7893\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 3s 10ms/step - loss: 0.1047 - accuracy: 0.8074 - val_loss: 0.1043 - val_accuracy: 0.8073\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 3s 10ms/step - loss: 0.1041 - accuracy: 0.8087 - val_loss: 0.1129 - val_accuracy: 0.7960\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 3s 10ms/step - loss: 0.1023 - accuracy: 0.8119 - val_loss: 0.1093 - val_accuracy: 0.7962\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 3s 10ms/step - loss: 0.1010 - accuracy: 0.8159 - val_loss: 0.1092 - val_accuracy: 0.7983\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 3s 10ms/step - loss: 0.1028 - accuracy: 0.8103 - val_loss: 0.1223 - val_accuracy: 0.7751\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 3s 10ms/step - loss: 0.0995 - accuracy: 0.8166 - val_loss: 0.1071 - val_accuracy: 0.8009\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 3s 10ms/step - loss: 0.0978 - accuracy: 0.8219 - val_loss: 0.1077 - val_accuracy: 0.8037\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 3s 9ms/step - loss: 0.0977 - accuracy: 0.8198 - val_loss: 0.1079 - val_accuracy: 0.8022\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 3s 10ms/step - loss: 0.0965 - accuracy: 0.8220 - val_loss: 0.1119 - val_accuracy: 0.7947\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=32, epochs=10,validation_data=(x_test, y_test), callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
